


2021-02-10 11:35:09,212 INFO   ||  AbstractConfig values:
   [org.apache.kafka.common.config.AbstractConfig]
2021-02-10 11:35:09,226 INFO   ||  [Worker clientId=connect-1, groupId=1] Connector apollo_logmnr-connector config updated   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:09,227 INFO   ||  [Worker clientId=connect-1, groupId=1] Rebalance started   [org.apache.kafka.connect.runtime.distributed.WorkerCoordinator]
2021-02-10 11:35:09,227 INFO   ||  [Worker clientId=connect-1, groupId=1] (Re-)joining group   [org.apache.kafka.clients.consumer.internals.AbstractCoordinator]
2021-02-10 11:35:09,232 INFO   ||  [Worker clientId=connect-1, groupId=1] Successfully joined group with generation Generation{generationId=10, memberId='connect-1-fdb56786-b220-4701-a31a-396b8fc30e9b', protocol='sessioned'}   [org.apache.kafka.clients.consumer.internals.AbstractCoordinator]
2021-02-10 11:35:09,240 INFO   ||  [Worker clientId=connect-1, groupId=1] Successfully synced group in generation Generation{generationId=10, memberId='connect-1-fdb56786-b220-4701-a31a-396b8fc30e9b', protocol='sessioned'}   [org.apache.kafka.clients.consumer.internals.AbstractCoordinator]
2021-02-10 11:35:09,240 INFO   ||  [Worker clientId=connect-1, groupId=1] Joined group at generation 10 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-fdb56786-b220-4701-a31a-396b8fc30e9b', leaderUrl='http://192.168.96.5:8083/', offset=12, connectorIds=[apollo_logmnr-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:09,241 INFO   ||  [Worker clientId=connect-1, groupId=1] Starting connectors and tasks using config offset 12   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:09,241 INFO   ||  [Worker clientId=connect-1, groupId=1] Starting connector apollo_logmnr-connector   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:09,242 INFO   ||  Creating connector apollo_logmnr-connector of type io.debezium.connector.oracle.OracleConnector   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:09,243 INFO   ||  SourceConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.SourceConnectorConfig]
2021-02-10 11:35:09,244 INFO   ||  EnrichedConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig]
2021-02-10 11:35:09,244 INFO   ||  Instantiated connector apollo_logmnr-connector with version 1.4.1.Final of type class io.debezium.connector.oracle.OracleConnector   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:09,245 INFO   ||  Finished creating connector apollo_logmnr-connector   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:09,246 INFO   ||  [Worker clientId=connect-1, groupId=1] Finished starting connectors and tasks   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:09,250 INFO   ||  SourceConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.SourceConnectorConfig]
2021-02-10 11:35:09,251 INFO   ||  EnrichedConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig]
2021-02-10 11:35:10,249 INFO   ||  [Worker clientId=connect-1, groupId=1] Tasks [apollo_logmnr-connector-0] configs updated   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:10,251 INFO   ||  [Worker clientId=connect-1, groupId=1] Handling task config update by restarting tasks []   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:10,253 INFO   ||  [Worker clientId=connect-1, groupId=1] Rebalance started   [org.apache.kafka.connect.runtime.distributed.WorkerCoordinator]
2021-02-10 11:35:10,254 INFO   ||  [Worker clientId=connect-1, groupId=1] (Re-)joining group   [org.apache.kafka.clients.consumer.internals.AbstractCoordinator]
2021-02-10 11:35:10,258 INFO   ||  [Worker clientId=connect-1, groupId=1] Successfully joined group with generation Generation{generationId=11, memberId='connect-1-fdb56786-b220-4701-a31a-396b8fc30e9b', protocol='sessioned'}   [org.apache.kafka.clients.consumer.internals.AbstractCoordinator]
2021-02-10 11:35:10,262 INFO   ||  [Worker clientId=connect-1, groupId=1] Successfully synced group in generation Generation{generationId=11, memberId='connect-1-fdb56786-b220-4701-a31a-396b8fc30e9b', protocol='sessioned'}   [org.apache.kafka.clients.consumer.internals.AbstractCoordinator]
2021-02-10 11:35:10,262 INFO   ||  [Worker clientId=connect-1, groupId=1] Joined group at generation 11 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-fdb56786-b220-4701-a31a-396b8fc30e9b', leaderUrl='http://192.168.96.5:8083/', offset=14, connectorIds=[apollo_logmnr-connector], taskIds=[apollo_logmnr-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:10,264 INFO   ||  [Worker clientId=connect-1, groupId=1] Starting connectors and tasks using config offset 14   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:10,265 INFO   ||  [Worker clientId=connect-1, groupId=1] Starting task apollo_logmnr-connector-0   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:10,266 INFO   ||  Creating task apollo_logmnr-connector-0   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:10,269 INFO   ||  ConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.ConnectorConfig]
2021-02-10 11:35:10,270 INFO   ||  EnrichedConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig]
2021-02-10 11:35:10,270 INFO   ||  TaskConfig values:
	task.class = class io.debezium.connector.oracle.OracleConnectorTask
   [org.apache.kafka.connect.runtime.TaskConfig]
2021-02-10 11:35:10,270 INFO   ||  Instantiated task apollo_logmnr-connector-0 with version 1.4.1.Final of type io.debezium.connector.oracle.OracleConnectorTask   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:10,270 INFO   ||  JsonConverterConfig values:
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
   [org.apache.kafka.connect.json.JsonConverterConfig]
2021-02-10 11:35:10,271 INFO   ||  Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task apollo_logmnr-connector-0 using the worker config   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:10,271 INFO   ||  JsonConverterConfig values:
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
   [org.apache.kafka.connect.json.JsonConverterConfig]
2021-02-10 11:35:10,271 INFO   ||  Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task apollo_logmnr-connector-0 using the worker config   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:10,271 INFO   ||  Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task apollo_logmnr-connector-0 using the worker config   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:10,273 INFO   ||  SourceConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.SourceConnectorConfig]
2021-02-10 11:35:10,275 INFO   ||  EnrichedConnectorConfig values:
	config.action.reload = restart
	connector.class = io.debezium.connector.oracle.OracleConnector
	errors.log.enable = true
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = apollo_logmnr-connector
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
   [org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig]
2021-02-10 11:35:10,276 INFO   ||  Initializing: org.apache.kafka.connect.runtime.TransformationChain{}   [org.apache.kafka.connect.runtime.Worker]
2021-02-10 11:35:10,281 INFO   ||  ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-apollo_logmnr-connector-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
   [org.apache.kafka.clients.producer.ProducerConfig]
2021-02-10 11:35:10,300 WARN   ||  The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config.   [org.apache.kafka.clients.producer.ProducerConfig]
2021-02-10 11:35:10,300 WARN   ||  The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config.   [org.apache.kafka.clients.producer.ProducerConfig]
2021-02-10 11:35:10,300 INFO   ||  Kafka version: 2.6.1   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,300 INFO   ||  Kafka commitId: 6b2021cd52659cef   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,300 INFO   ||  Kafka startTimeMs: 1612956910300   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,306 INFO   ||  [Worker clientId=connect-1, groupId=1] Finished starting connectors and tasks   [org.apache.kafka.connect.runtime.distributed.DistributedHerder]
2021-02-10 11:35:10,313 WARN   ||  Using configuration property "table.whitelist" is deprecated and will be removed in future versions. Please use "table.include.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,314 WARN   ||  Using configuration property "table.blacklist" is deprecated and will be removed in future versions. Please use "table.exclude.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,314 WARN   ||  Using configuration property "table.whitelist" is deprecated and will be removed in future versions. Please use "table.include.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,315 WARN   ||  Using configuration property "table.blacklist" is deprecated and will be removed in future versions. Please use "table.exclude.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,315 INFO   ||  Starting OracleConnectorTask with configuration:   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,315 INFO   ||     connector.class = io.debezium.connector.oracle.OracleConnector   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,316 INFO   ||     database.user = c##logminer   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,316 INFO   ||     database.dbname = XE   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,316 INFO   ||     tasks.max = 1   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,316 INFO   ||     database.connection.adapter = logminer   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,316 INFO   ||     database.history.kafka.bootstrap.servers = kafka:9092   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,316 INFO   ||     database.history.kafka.topic = schema-changes.apollo_prop   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,317 INFO   ||     table.white.list = PACKAGETYPE   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,317 INFO   ||     database.server.name = dbz_oracle   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,317 INFO   ||     database.tablename.case.insensitive = true   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,317 INFO   ||     database.port = 1521   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,317 INFO   ||     task.class = io.debezium.connector.oracle.OracleConnectorTask   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,318 INFO   ||     database.hostname = 192.168.96.2   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,318 INFO   ||     database.schema = APOLLO_PROP   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,318 INFO   ||     database.password = ********   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,320 INFO   ||     name = apollo_logmnr-connector   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,320 INFO   ||     database.oracle.version = 11   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,320 INFO   ||     errors.log.enable = true   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,320 INFO   ||     snapshot.mode = schema_only   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,320 INFO   ||     snapshot.lock.timeout.ms = 5000   [io.debezium.connector.common.BaseSourceTask]
2021-02-10 11:35:10,321 WARN   ||  Using configuration property "schema.whitelist" is deprecated and will be removed in future versions. Please use "schema.include.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,321 WARN   ||  Using configuration property "schema.blacklist" is deprecated and will be removed in future versions. Please use "schema.exclude.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,321 WARN   ||  Using configuration property "table.whitelist" is deprecated and will be removed in future versions. Please use "table.include.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,321 WARN   ||  Using configuration property "table.blacklist" is deprecated and will be removed in future versions. Please use "table.exclude.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,323 INFO   ||  [Producer clientId=connector-producer-apollo_logmnr-connector-0] Cluster ID: fD9kbqPYSSuS8FHCFSp5Dg   [org.apache.kafka.clients.Metadata]
2021-02-10 11:35:10,323 WARN   ||  Using configuration property "column.blacklist" is deprecated and will be removed in future versions. Please use "column.exclude.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:10,327 INFO   ||  KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=dbz_oracle-dbhistory, bootstrap.servers=kafka:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=dbz_oracle-dbhistory}   [io.debezium.relational.history.KafkaDatabaseHistory]
2021-02-10 11:35:10,328 INFO   ||  KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=kafka:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=dbz_oracle-dbhistory, linger.ms=0}   [io.debezium.relational.history.KafkaDatabaseHistory]
2021-02-10 11:35:10,329 INFO   ||  Requested thread factory for connector OracleConnector, id = dbz_oracle named = db-history-config-check   [io.debezium.util.Threads]
2021-02-10 11:35:10,330 INFO   ||  ProducerConfig values:
	acks = 1
	batch.size = 32768
	bootstrap.servers = [kafka:9092]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = dbz_oracle-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
   [org.apache.kafka.clients.producer.ProducerConfig]
2021-02-10 11:35:10,340 INFO   ||  Kafka version: 2.6.1   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,340 INFO   ||  Kafka commitId: 6b2021cd52659cef   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,340 INFO   ||  Kafka startTimeMs: 1612956910339   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,342 INFO   ||  ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = dbz_oracle-dbhistory
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dbz_oracle-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
   [org.apache.kafka.clients.consumer.ConsumerConfig]
2021-02-10 11:35:10,357 INFO   ||  Kafka version: 2.6.1   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,359 INFO   ||  [Producer clientId=dbz_oracle-dbhistory] Cluster ID: fD9kbqPYSSuS8FHCFSp5Dg   [org.apache.kafka.clients.Metadata]
2021-02-10 11:35:10,359 INFO   ||  Kafka commitId: 6b2021cd52659cef   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,363 INFO   ||  Kafka startTimeMs: 1612956910357   [org.apache.kafka.common.utils.AppInfoParser]
2021-02-10 11:35:10,375 INFO   ||  [Consumer clientId=dbz_oracle-dbhistory, groupId=dbz_oracle-dbhistory] Cluster ID: fD9kbqPYSSuS8FHCFSp5Dg   [org.apache.kafka.clients.Metadata]
2021-02-10 11:35:10,841 INFO   ||  Requested thread factory for connector OracleConnector, id = dbz_oracle named = change-event-source-coordinator   [io.debezium.util.Threads]
2021-02-10 11:35:10,841 INFO   ||  Creating thread debezium-oracleconnector-dbz_oracle-change-event-source-coordinator   [io.debezium.util.Threads]
2021-02-10 11:35:10,842 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Source task finished initialization and start   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:35:10,844 INFO   ||  Metrics registered   [io.debezium.pipeline.ChangeEventSourceCoordinator]
2021-02-10 11:35:10,844 INFO   ||  Context created   [io.debezium.pipeline.ChangeEventSourceCoordinator]
2021-02-10 11:35:10,846 INFO   ||  Snapshot step 1 - Preparing   [io.debezium.relational.RelationalSnapshotChangeEventSource]
2021-02-10 11:35:10,899 INFO   ||  Snapshot step 2 - Determining captured tables   [io.debezium.relational.RelationalSnapshotChangeEventSource]
2021-02-10 11:35:11,214 WARN   ||  Using configuration property "table.whitelist" is deprecated and will be removed in future versions. Please use "table.include.list" instead.   [io.debezium.config.Configuration]
2021-02-10 11:35:11,215 INFO   ||  Snapshot step 3 - Locking captured tables [XE.APOLLO_PROP.COMERCIALPACKAGECONVERSION, XE.APOLLO_PROP.COMERCIALPRODUCT, XE.APOLLO_PROP.COMERCIALPRODUCTCONVERSION, XE.APOLLO_PROP.PACKAGETYPE, XE.APOLLO_PROP.PACKAGE_CFG]   [io.debezium.relational.RelationalSnapshotChangeEventSource]
2021-02-10 11:35:11,238 INFO   ||  Snapshot step 4 - Determining snapshot offset   [io.debezium.relational.RelationalSnapshotChangeEventSource]
2021-02-10 11:35:11,336 INFO   ||  Snapshot step 5 - Reading structure of captured tables   [io.debezium.relational.RelationalSnapshotChangeEventSource]
2021-02-10 11:35:12,880 INFO   ||  Snapshot step 6 - Persisting schema history   [io.debezium.relational.RelationalSnapshotChangeEventSource]
2021-02-10 11:35:13,965 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'COMERCIALPACKAGEID'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:13,967 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'ACTDATE'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,132 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'COMERCIALPRODUCTNAME'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,133 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'ACTDATE'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,134 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'EFFECTIVEDATEINI'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,135 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'EFFECTIVEDATEEND'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,136 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'ERPID'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,139 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'MODALITYCONVERSION'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,139 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'MARKETINGNAME'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,236 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'ACTDATE'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,326 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'PACKAGETYPENAME'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,326 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'ACTDATE'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,424 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'PACKAGEDESC'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,425 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'EFFECTIVEDATEINI'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,425 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'EFFECTIVEDATEEND'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,426 INFO   ||  JdbcValueConverters returned 'org.apache.kafka.connect.data.SchemaBuilder' for column 'ACTDATE'   [io.debezium.connector.oracle.OracleValueConverters]
2021-02-10 11:35:14,434 INFO   ||  Snapshot step 7 - Skipping snapshotting of data   [io.debezium.relational.RelationalSnapshotChangeEventSource]
2021-02-10 11:35:14,435 INFO   ||  Snapshot - Final stage   [io.debezium.pipeline.source.AbstractSnapshotChangeEventSource]
2021-02-10 11:35:14,436 INFO   ||  Snapshot ended with SnapshotResult [status=COMPLETED, offset=OracleOffsetContext [scn=415430]]   [io.debezium.pipeline.ChangeEventSourceCoordinator]
2021-02-10 11:35:14,437 INFO   ||  Connected metrics set to 'true'   [io.debezium.pipeline.metrics.StreamingChangeEventSourceMetrics]
2021-02-10 11:35:14,438 INFO   ||  Starting streaming   [io.debezium.pipeline.ChangeEventSourceCoordinator]
2021-02-10 11:35:14,440 INFO   ||  Requested thread factory for connector OracleConnector, id = dbz_oracle named = transactional-buffer   [io.debezium.util.Threads]
2021-02-10 11:35:14,463 WARN   ||  [Producer clientId=connector-producer-apollo_logmnr-connector-0] Error while fetching metadata with correlation id 3 : {dbz_oracle=LEADER_NOT_AVAILABLE}   [org.apache.kafka.clients.NetworkClient]
2021-02-10 11:36:10,235 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:36:10,238 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:36:10,296 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Finished commitOffsets successfully in 58 ms   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:37:10,227 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:37:10,230 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:38:10,162 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:38:10,162 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:39:10,095 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:39:10,095 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:40:10,028 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:40:10,028 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:41:09,960 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:41:09,960 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:42:09,893 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:42:09,893 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:43:09,826 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:43:09,826 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:44:09,758 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:44:09,759 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:45:09,691 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:45:09,692 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:46:09,625 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:46:09,626 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:47:09,559 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} Committing offsets   [org.apache.kafka.connect.runtime.WorkerSourceTask]
2021-02-10 11:47:09,559 INFO   ||  WorkerSourceTask{id=apollo_logmnr-connector-0} flushing 0 outstanding messages for offset commit   [org.apache.kafka.connect.runtime.WorkerSourceTask]
